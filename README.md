# ğŸ¬ YouTube RAG Q\&A Assistant

A powerful local Retrieval-Augmented Generation (RAG) system that turns any YouTube video into a knowledge base. Paste a video URL, transcribe its content, generate semantic embeddings, and query it with natural language â€” all locally with no API keys required.

Built using:

* `faster-whisper` for fast, accurate speech-to-text
* `thenlper/gte-small` for embedding transcript chunks
* FAISS for semantic search
* `llama-cpp-python` with Mistral-7B-Instruct GGUF for local LLM answers
* Streamlit for a clean and interactive frontend

---

## âœ¨ Features

* ğŸ”— Paste any YouTube video link
* ğŸ”Š Download and transcribe audio using Whisper (faster-whisper)
* ğŸ“š Chunk and embed transcripts with sentence-transformers
* ğŸ” Retrieve relevant transcript sections using FAISS
* ğŸ¤– Answer questions with a local quantized LLM (Mistral-7B)
* ğŸ›ï¸ Customizable temperature for creativity
* ğŸ“¥ Download transcript
* ğŸï¸ Watch video thumbnail preview

---

## ğŸ› ï¸ Requirements

* âœ… Python 3.10+
* âœ… [FFmpeg](https://ffmpeg.org/download.html) â€“ make sure it's added to your system PATH
* âœ… `llama-cpp-python` â€“ for running local LLMs with GPU/CPU (cuBLAS preferred for GPU)
* âœ… Quantized GGUF model â€“ e.g., `mistral-7b-instruct-v0.1.Q4_K_M.gguf`
* âœ… Whisper model weights â€“ auto-downloaded on first run (uses `faster-whisper`)
* âœ… Git LFS â€“ required if cloning GGUF models from Hugging Face or GitHub

---

## ğŸ“¦ Installation

```bash
git clone https://github.com/Gtest111/Ragna-Vid
cd youtube-rag-qa

# Create and activate virtual environment
python -m venv venv
venv\Scripts\activate         # On Windows
# OR
source venv/bin/activate      # On macOS/Linux

# Install Python dependencies
pip install -r requirements.txt
```

---

## ğŸ”§ Download Required Models

### 1. GGUF Model (Mistral)

* Download from Hugging Face or TheBloke:
  [mistral-7b-instruct-v0.1.Q4\_K\_M.gguf](https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF)
* Place the `.gguf` file in the `models/` directory:

```bash
models/mistral-7b-instruct-v0.1.Q4_K_M.gguf
```

### 2. Whisper

* No manual setup required. The `faster-whisper` model will be downloaded automatically (default: `base`).

### 3. Embedding Model

* Uses [thenlper/gte-small](https://huggingface.co/thenlper/gte-small) from Hugging Face
* Automatically fetched via `sentence-transformers`

---

## â–¶ï¸ Run the App

```bash
streamlit run app.py
```

---

## ğŸ“ Project Structure

```
youtube-rag-qa/
â”œâ”€â”€ app.py                      # Streamlit UI
â”œâ”€â”€ rag_pipeline.py            # End-to-end RAG pipeline
â”œâ”€â”€ downloader/
â”‚   â””â”€â”€ audio_downloader.py
â”œâ”€â”€ transcription/
â”‚   â””â”€â”€ transcriber.py
â”œâ”€â”€ chunking/
â”‚   â””â”€â”€ chunker.py
â”œâ”€â”€ embeddings/
â”‚   â””â”€â”€ embedder.py
â”œâ”€â”€ vectorstore/
â”‚   â””â”€â”€ vector_index.py
â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ retriever.py
â”‚   â””â”€â”€ qa_engine.py
â”œâ”€â”€ models/                    # Place GGUF model here
â”œâ”€â”€ cache/                     # Stores audio, transcript, chunks, FAISS index
â””â”€â”€ requirements.txt
```

---

## ğŸ“Œ Future Improvements

* âœ… Add chat-like memory support (multi-turn QA)
* âœ… Live transcript editor for chunk refining
* âœ… Model selector with temperature, top-k toggles
* âœ… Switch between multiple GGUF models (optional)

---

## ğŸ’¡ Credits

* [Mistral-7B-Instruct GGUF](https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF)
* [faster-whisper](https://github.com/guillaumekln/faster-whisper)
* [FAISS](https://github.com/facebookresearch/faiss)
* [sentence-transformers](https://www.sbert.net/)
* [Streamlit](https://streamlit.io/)

---

## ğŸ“œ License

This project is licensed under MIT. Use responsibly.

---

Made with ğŸ’™ by Yajuvendrasinh Chudasama
